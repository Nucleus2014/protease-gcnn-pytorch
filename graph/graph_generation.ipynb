{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Generation Rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyRosetta-4 2019 [Rosetta PyRosetta4.conda.mac.python37.Release 2019.30+release.0da57b43256586e78d19865fc7cdcf9ccfb99d66 2019-07-21T15:08:17] retrieved from: http://www.pyrosetta.org\n",
      "(C) Copyright Rosetta Commons Member Institutions. Created in JHU by Sergey Lyskov and PyRosetta Team.\n",
      "\u001b[0mcore.init: \u001b[0mChecking for fconfig files in pwd and ./rosetta/flags\n",
      "\u001b[0mcore.init: \u001b[0mRosetta version: PyRosetta4.conda.mac.python37.Release r228 2019.30+release.0da57b43256 0da57b43256586e78d19865fc7cdcf9ccfb99d66 http://www.pyrosetta.org 2019-07-21T15:08:17\n",
      "\u001b[0mcore.init: \u001b[0mcommand: PyRosetta -ex1 -ex2aro -database /Users/cplu/anaconda3/envs/pyrosetta4/lib/python3.7/site-packages/pyrosetta/database\n",
      "\u001b[0mcore.init: \u001b[0m'RNG device' seed mode, using '/dev/urandom', seed=1560523888 seed_offset=0 real_seed=1560523888\n",
      "\u001b[0mcore.init.random: \u001b[0mRandomGenerator:init: Normal mode, seed=1560523888 RG_type=mt19937\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import pyrosetta as pr\n",
    "from pyrosetta import *\n",
    "from pyrosetta.rosetta.core.scoring import *\n",
    "from pyrosetta.rosetta.core.pose import get_chain_from_chain_id, center_of_mass\n",
    "from pyrosetta.rosetta.core.select.residue_selector import ChainSelector, \\\n",
    "ResidueIndexSelector, NeighborhoodResidueSelector\n",
    "from pyrosetta.rosetta.core.select import get_residues_from_subset\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pr.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mcore.scoring.ScoreFunctionFactory: \u001b[0mSCOREFUNCTION: \u001b[32mref2015\u001b[0m\n",
      "\u001b[0mcore.scoring.etable: \u001b[0mStarting energy table calculation\n",
      "\u001b[0mcore.scoring.etable: \u001b[0msmooth_etable: changing atr/rep split to bottom of energy well\n",
      "\u001b[0mcore.scoring.etable: \u001b[0msmooth_etable: spline smoothing lj etables (maxdis = 6)\n",
      "\u001b[0mcore.scoring.etable: \u001b[0msmooth_etable: spline smoothing solvation etables (max_dis = 6)\n",
      "\u001b[0mcore.scoring.etable: \u001b[0mFinished calculating energy tables.\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/hbonds/ref2015_params/HBPoly1D.csv\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/hbonds/ref2015_params/HBFadeIntervals.csv\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/hbonds/ref2015_params/HBEval.csv\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/hbonds/ref2015_params/DonStrength.csv\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/hbonds/ref2015_params/AccStrength.csv\n",
      "\u001b[0mcore.chemical.GlobalResidueTypeSet: \u001b[0mFinished initializing fa_standard residue type set.  Created 980 residue types\n",
      "\u001b[0mcore.chemical.GlobalResidueTypeSet: \u001b[0mTotal time to initialize 1.30032 seconds.\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/rama/fd/all.ramaProb\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/rama/fd/prepro.ramaProb\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/omega/omega_ppdep.all.txt\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/omega/omega_ppdep.gly.txt\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/omega/omega_ppdep.pro.txt\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/omega/omega_ppdep.valile.txt\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/P_AA_pp/P_AA\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/P_AA_pp/P_AA_n\n",
      "\u001b[0mcore.scoring.P_AA: \u001b[0mshapovalov_lib::shap_p_aa_pp_smooth_level of 1( aka low_smooth ) got activated.\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/P_AA_pp/shapovalov/10deg/kappa131/a20.prop\n"
     ]
    }
   ],
   "source": [
    "#preset\n",
    "sfxn = get_fa_scorefxn()\n",
    "classifier_path = \"classifications/\"\n",
    "data_path = \"../data\" \n",
    "pdb_path = \"crystal_structures\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser.add_argument(\"-o\", \"--output\", help=\"Output name\")\n",
    "    parser.add_argument(\"-pr_path\", \"--protease_path\", default = \"\", help=\"Path to silent pose directory for protease\")\n",
    "    parser.add_argument(\"-class\", \"--classification_file\", default = \"\", help=\"Name of txt for sequences to use, must be in folder\")\n",
    "    parser.add_argument(\"-index_p1\", \"--index_p1\", default = 7, help=\"Index of p1 in the pdb, starting from 1.\")\n",
    "    parser.add_argument(\"-prot\", \"--protease\", default=\"HCV.pdb\", help=\"Protease pdb name.\")\n",
    "    parser.add_argument(\"-d\",\"--select_distance\",default=10, help=\"Distance for NeighborSelector\")\n",
    "    return parser.parse_args()\n",
    "    # parser.add_argument(\"-si\", \"--size_interface\", help=\"|Interface|\", type = int)\n",
    "    # parser.add_argument(\"-is\", \"--interface_selector\", help=\"Way Interface Is Selected, either k_nearest or residue_wise currently\")\n",
    "    # parser.add_argument(\"-unsafe\", \"--unsafe\", help=\"Overwrite datasets\", action='store_true')\n",
    "    # parser.add_argument(\"-params\", \"--params\", default = \"\", help= \"parameters dict for the graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = args.class\n",
    "output = args.output\n",
    "pr_path = args.protease_path\n",
    "index_p1 = args.index_p1\n",
    "protease = args.protease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):\n",
    "    logger = logging.getLogger()\n",
    "    if debug:\n",
    "        level = logging.DEBUG\n",
    "    else:\n",
    "        level = logging.INFO\n",
    "    logger.setLevel(level)\n",
    "    if saving:\n",
    "        info_file_handler = logging.FileHandler(logpath, mode=\"a\")\n",
    "        info_file_handler.setLevel(level)\n",
    "        logger.addHandler(info_file_handler)\n",
    "    if displaying:\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(level)\n",
    "        logger.addHandler(console_handler)\n",
    "    logger.info(filepath)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        logger.info(f.read())\n",
    "\n",
    "    for f in package_files:\n",
    "        logger.info(f)\n",
    "        with open(f, \"r\") as package_f:\n",
    "            logger.info(package_f.read())\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(logpath=os.path.join(data_path, 'logs'), filepath=os.path.abspath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = \"sample.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in labels and sequences\n",
    "try:\n",
    "    df = pd.read_csv(os.path.join(classifier_path, class_file), sep = \"\\t\")\n",
    "    labels = list(df[\"Result\"])\n",
    "    sequences = list(df[\"Sequence\"])\n",
    "except:\n",
    "    raise ValueError(\"Path either invalid to classsifications or not properly formatted. \\\n",
    "Please check template experimental_binary_classifications.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AYYYEPC.ASHL</td>\n",
       "      <td>CLEAVED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sequence   Result\n",
       "0  AYYYEPC.ASHL  CLEAVED"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silent_file(sequence, path_to_silent_files):\n",
    "    \"\"\"This just returns an absolute path to the silent file (windows specific possibly) false if not found\"\"\"\n",
    "    silent_file = None\n",
    "    for silent in os.listdir(path_to_silent_files):\n",
    "        correct = True\n",
    "        for counter, char in enumerate(silent):\n",
    "            if char != sequence[counter] and char != \"_\":\n",
    "                correct = False\n",
    "                break\n",
    "        if correct:\n",
    "            silent_file = silent\n",
    "            break\n",
    "    if silent_file == None:\n",
    "        print(\"Silent dir for {} not found in {}!\".format(sequence, path_to_silent_files))\n",
    "        return False\n",
    "    silent_dir = os.path.join(path_to_silent_files, silent_file)\n",
    "    silent_file_path = os.path.join(silent_dir, silent_file)\n",
    "    \n",
    "    if os.path.exists(silent_file_path):\n",
    "        return silent_file_path\n",
    "    else:\n",
    "        print(\"Silent file for {} not found {}!\".format(sequence, silent_file_path))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent = get_silent_file(\"AYAKEPC.ASHL\",\"silent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'silent/AYAK__C.ASHL/AYAK__C.ASHL'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedirs(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_silent(sequence, path_to_silent_files):\n",
    "    silent_file = get_silent_file(sequence, path_to_silent_files)\n",
    "    if not silent_file:\n",
    "            return \"Error: No Silent\"\n",
    "    with open(silent_file) as f:\n",
    "        lineList = f.readlines()\n",
    "    tag_ending = \"substrate.{}\".format(sequence)\n",
    "    found, done = (False, False)\n",
    "    ind, start, end, last_score = (0,0,0,0)\n",
    "    while ind < len(lineList) and not done:\n",
    "        x = lineList[ind]\n",
    "        if \"SCORE\" in x:\n",
    "            last_score = ind\n",
    "        if not found and \"ANNOTATED_SEQUENCE: \" in x and tag_ending in x:\n",
    "            start = last_score\n",
    "            found = True\n",
    "        elif found and \"ANNOTATED_SEQUENCE: \" in x:\n",
    "            end = last_score\n",
    "            done = True\n",
    "        ind += 1\n",
    "    if not found:\n",
    "        print(\"The requested sequence {} was not found in the silent file {} (Parsing Error)\".format(sequence, silent_file))\n",
    "        raise ValueError(\"The requested sequence {} was not found in the silent file {} (Parsing Error)\".format(sequence, silent_file))\n",
    "    if not done:\n",
    "        end = len(lineList)\n",
    "    \n",
    "    filename = sequence + str(np.random.randint(10000, 100000))\n",
    "    path_bin = os.path.join(os.getcwd(), \"bin\")\n",
    "    makedirs(path_bin)\n",
    "    filename = os.path.join(path_bin, filename)\n",
    "    with open(filename, \"w\") as f:\n",
    "        # add header\n",
    "        for i in range(3):\n",
    "            f.write(lineList[i])\n",
    "        # add binary information\n",
    "        for i in range(start, end):\n",
    "            f.write(lineList[i])\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = generate_dummy_silent(\"AYYYEPC.ASHL\",\"silent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/cplu/Downloads/Documents/RESEARCH/GCNN/protease-gcnn-pytorch/graph/bin/AYYYEPC.ASHL58135'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mcore.io.silent.SilentFileData: \u001b[0mReading all structures from /Users/cplu/Downloads/Documents/RESEARCH/GCNN/protease-gcnn-pytorch/graph/bin/AYYYEPC.ASHL58135\n",
      "\u001b[0mcore.io.silent.SilentFileData: \u001b[0mFinished reading 1 structures from /Users/cplu/Downloads/Documents/RESEARCH/GCNN/protease-gcnn-pytorch/graph/bin/AYYYEPC.ASHL58135\n"
     ]
    }
   ],
   "source": [
    "for pose in poses_from_silent(filename):\n",
    "    ret = pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyrosetta.rosetta.core.pose.Pose at 0x145af4ce0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_from_pdb(sequence, path):\n",
    "    for pdb in os.listdir(path):\n",
    "        if pdb == sequence:\n",
    "            ret = pose_from_pdb(os.path.join(path, pdb))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose(sequence, path, is_silent = True):\n",
    "    if is_silent == True:\n",
    "        try:\n",
    "            filename = generate_dummy_silent(sequence, path)\n",
    "            for pose in poses_from_silent(filename):\n",
    "                ret = pose\n",
    "            os.remove(filename)\n",
    "            return ret\n",
    "        except:\n",
    "            return \"Error: Invalid Silent\"        \n",
    "    else:\n",
    "        ret = get_pose_from_pdb(sequence) # need to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mcore.io.silent.SilentFileData: \u001b[0mReading all structures from /Users/cplu/Downloads/Documents/RESEARCH/GCNN/protease-gcnn-pytorch/graph/bin/AYYYEPC.ASHL75824\n",
      "\u001b[0mcore.io.silent.SilentFileData: \u001b[0mFinished reading 1 structures from /Users/cplu/Downloads/Documents/RESEARCH/GCNN/protease-gcnn-pytorch/graph/bin/AYYYEPC.ASHL75824\n"
     ]
    }
   ],
   "source": [
    "pose = get_pose(\"AYYYEPC.ASHL\",\"silent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.dump_pdb(\"AYYYEPC.ASHL.pdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_substrate(pose):\n",
    "    \"\"\"Takes a pose and returns the indices of the substrate.\"\"\"\n",
    "    # get substrate with built in selector\n",
    "    num_chains = pose.num_chains()\n",
    "    chain_name = get_chain_from_chain_id(num_chains, pose)\n",
    "    sub_sel = ChainSelector(chain_name)\n",
    "    v1 = sub_sel.apply(pose)\n",
    "    substrate_indices = []\n",
    "    for count,ele in enumerate(v1):\n",
    "        if ele:\n",
    "            substrate_indices.append(count + 1)\n",
    "    return substrate_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "substrate_ind = index_substrate(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substrate_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_p1 = \"AYYYEPC.ASHL\".index(\".\")\n",
    "index_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_substrate_cut_site(pose, index_p1 = 7, upstream_buffer = 6, downstream_buffer = -1, protease = None):\n",
    "    \"\"\"This function takes the ROSETTA INDEX of the P1 residue for a substrate within its chain, a pose, and\n",
    "    the number of upstream and downstream residues to model, and returns the indices of the substrate. If the\n",
    "    buffer actually goes OOB of the substrate, a None type for that ind is instead returned for 0 pad modelling\"\"\"\n",
    "    ind_sub = index_substrate(pose)\n",
    "    ind_active = []\n",
    "    for i in range(-upstream_buffer, downstream_buffer):\n",
    "        index_interest = i + index_p1\n",
    "        if index_interest < 0 or index_interest >= len(ind_sub):\n",
    "            ind_active.append(None)\n",
    "        else:\n",
    "            ind_active.append(ind_sub[index_interest])\n",
    "    return ind_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[198, 199, 200, 201, 202]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try\n",
    "cutsite_ind = index_substrate_cut_site(pose)\n",
    "cutsite_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selector_to_list(pose, selector):\n",
    "    \"\"\"\n",
    "    Produces a list of residues from a pose identified by a given selector\n",
    "    \"\"\"\n",
    "\n",
    "    return list(get_residues_from_subset(selector.apply(pose)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_interface(pose,\n",
    "                    active_site,\n",
    "                    substrate_indices,\n",
    "                    d=10):\n",
    "    \"\"\"This function takes a pose and a number of interface/substrate to consider and returns interface indices. The\n",
    "    value k and pose are not used...\"\"\"\n",
    "    \n",
    "    # Selection for neighbor residues\n",
    "    focus_res = ','.join([str(j) for j in substrate_indices])\n",
    "    focus_selector = ResidueIndexSelector(focus_res)\n",
    "\n",
    "    interface = NeighborhoodResidueSelector()\n",
    "    interface.set_focus_selector(focus_selector)\n",
    "    interface.set_distance(d)\n",
    "    interface.set_include_focus_in_subset(False)\n",
    "    interface_indices = selector_to_list(pose, interface)\n",
    "    interface_indices.sort()\n",
    "            \n",
    "    return interface_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try\n",
    "index_p1 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/elec_cp_reps.dat\n",
      "\u001b[0mcore.scoring.elec.util: \u001b[0mRead 40 countpair representative atoms\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mshapovalov_lib_fixes_enable option is true.\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mshapovalov_lib::shap_dun10_smooth_level of 1( aka lowest_smooth ) got activated.\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mBinary rotamer library selected: /Users/cplu/anaconda3/envs/pyrosetta4/lib/python3.7/site-packages/pyrosetta/database/rotamer/shapovalov/StpDwn_0-0-0/Dunbrack10.lib.bin\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mUsing Dunbrack library binary file '/Users/cplu/anaconda3/envs/pyrosetta4/lib/python3.7/site-packages/pyrosetta/database/rotamer/shapovalov/StpDwn_0-0-0/Dunbrack10.lib.bin'.\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mDunbrack 2010 library took 0.302067 seconds to load from binary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-483.2861533494107"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfxn.score(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mcore.import_pose.import_pose: \u001b[0mFile 'crystal_structures/HCV.pdb' automatically determined to be of type PDB\n",
      "\u001b[0mbasic.io.database: \u001b[0mDatabase file opened: scoring/score_functions/elec_cp_reps.dat\n",
      "\u001b[0mcore.scoring.elec.util: \u001b[0mRead 40 countpair representative atoms\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mshapovalov_lib_fixes_enable option is true.\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mshapovalov_lib::shap_dun10_smooth_level of 1( aka lowest_smooth ) got activated.\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mBinary rotamer library selected: /Users/cplu/anaconda3/envs/pyrosetta4/lib/python3.7/site-packages/pyrosetta/database/rotamer/shapovalov/StpDwn_0-0-0/Dunbrack10.lib.bin\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mUsing Dunbrack library binary file '/Users/cplu/anaconda3/envs/pyrosetta4/lib/python3.7/site-packages/pyrosetta/database/rotamer/shapovalov/StpDwn_0-0-0/Dunbrack10.lib.bin'.\n",
      "\u001b[0mcore.pack.dunbrack.RotamerLibrary: \u001b[0mDunbrack 2010 library took 0.321671 seconds to load from binary\n"
     ]
    }
   ],
   "source": [
    "hcv_pose = pose_from_pdb(os.path.join(pdb_path, \"HCV.pdb\"))\n",
    "sfxn.score(hcv_pose)\n",
    "interface_ind = index_interface(hcv_pose, cutsite_ind, substrate_ind, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interface_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind_from_protease(protease_name, pdb_path, index_p1, dis, sfxn):\n",
    "    # load default pose as original\n",
    "    pose = pose_from_pdb(os.path.join(pdb_path, protease_name))\n",
    "    sfxn.score(pose)\n",
    "    substrate_ind = index_substrate(pose) #the whole substrate\n",
    "    cutsite_ind = index_substrate_cut_site(pose, index_p1) #p2-p6 on the substrate\n",
    "    interface_ind = index_interface(pose, cutsite_ind, substrate_ind, dis)\n",
    "    return cutsite_ind, interface_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mcore.import_pose.import_pose: \u001b[0mFile 'crystal_structures/HCV.pdb' automatically determined to be of type PDB\n"
     ]
    }
   ],
   "source": [
    "#try\n",
    "cutsite_ind, interface_ind = get_ind_from_protease(\"HCV.pdb\", pdb_path, index_p1, 10, sfxn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'198,199,200,201,202'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join([str(u) for u in cutsite_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GSVVIVGRIILSGRGGPITAYAQQTRGLLGCIITSLTGRDKNQVEGEVQIVSTAAQTFLATCINGVCWTVYHGAGTRTIASPKGPVIQMYTNVDQDLVGWPASQGTRSLTPCTCGSSDLYLVTRHADVIPVRRRGDSRGSLLSPRPISYLKGSSGGPLLCPAGHAVGIFRAAVCTRGVAKAVDFIPVENLETTMRSAYYYEPCASHL'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      22.51380220451573      -23.18137728952420       40.13473036273557\n"
     ]
    }
   ],
   "source": [
    "print(center_of_mass(pose, 1, len(pose.sequence())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class protein_graph:\n",
    "    \"\"\"This class is going to hold a graphical representation of a protein. It can be generated from two sources:\n",
    "    a pose object, or the file path of a pdb. Since we are attempting to model a substrate/protein complex,\n",
    "    the substrate and interface indices are ROSETTA(starting at 1) based indexes. When specified, these indices are\n",
    "    the indices that are used as nodes. When not supplied, all indices are used. It is assumed that:\n",
    "    \n",
    "    The substrate's indices are the last in the pdb/pose\n",
    "    When supplied interface and substrate are non-zero length\n",
    "    The intersection of substrate and interface indices is empty\n",
    "    Only canonical amino acids are not supported\n",
    "\n",
    "    Possible Values:\n",
    "    energy_terms = [fa_intra_sol_xover4, fa_intra_rep, rama_prepro, omega, p_aa_pp, fa_dun, ref]\n",
    "    energy_edge_terms = [pro_close, fa_atr, fa_rep, fa_sol, fa_elec, lk_ball_wtd]\"\"\"\n",
    "    \n",
    "    def __init__ (self, substrate_indices = None,\n",
    "                  interface_indices = None,\n",
    "                  pdb_file_path = None,\n",
    "                  pose = None,\n",
    "                  params = dict(),\n",
    "                  sfxn = None):\n",
    "\n",
    "        # assure user provided a source\n",
    "        if pdb_file_path == None and pose == None:\n",
    "            raise PathNotDeclaredError(\"No pose or pdb path provided\")\n",
    "        \n",
    "        # make pose from pdb\n",
    "        if pdb_file_path != None:\n",
    "            try:\n",
    "                cleanATOM(pdb_file_path)##### Need to fix this #####\n",
    "                pose = pose_from_pdb(pdb_file_path)\n",
    "            except:\n",
    "                raise PathNotDeclaredError(\"Failed to generate pose, file path invalid or other issue\")\n",
    "        \n",
    "        # if substrate or interface indices are given we will make vertice_arr specially tailored\n",
    "        ls = substrate_indices + interface_indices\n",
    "        vertice_arr = np.array(ls)\n",
    "        interface_indices = np.array(interface_indices)\n",
    "        substrate_indices = np.array(substrate_indices)\n",
    "        \n",
    "        # Get All Node Features\n",
    "        if params[\"amino_acids\"]: num_amino = 20\n",
    "        else: num_amino = 0\n",
    "        num_dim_sine = params[\"sinusoidal_encoding\"]\n",
    "        energy_terms = len(params[\"energy_terms\"])\n",
    "        if params[\"coordinates\"]: num_coord = 3\n",
    "        else: num_coord = 0\n",
    "        \n",
    "        # Make and Apply Score Function\n",
    "        if sfxn == None: sfxn = get_fa_scorefxn()\n",
    "        sfxn(pose)\n",
    "        energies = pose.energies()\n",
    "        \n",
    "        # Determine N (number of residues)\n",
    "        N = len(vertice_arr)\n",
    "        \n",
    "        # Determine F (number of node features)\n",
    "        F = sum([num_amino, num_dim_sine, energy_terms, num_coord])\n",
    "        if params[\"substrate_boolean\"]: F += 1\n",
    "        \n",
    "        # Initialize V (Feature Tensor NxF)\n",
    "        self.V = np.zeros(shape = (N, F))\n",
    "        \n",
    "        # Determine M (number of edge features)\n",
    "        M = 0\n",
    "#         if params[\"distance\"]: M += 1\n",
    "        M += len(params[\"energy_edge_terms\"])\n",
    "        if params[\"interface_edge\"]: M += 1\n",
    "        if params[\"covalent_edge\"]: M += 1\n",
    "        if params[\"hbond\"]: M += 1\n",
    "        # initialize A (Multiple Adj. Mat. NxNxM)\n",
    "        self.A = np.zeros(shape = (N, N, M))\n",
    "        counter_F = 0\n",
    "        counter_M = 0\n",
    "\n",
    "        # One Hot Vectors for Amino Acid Type\n",
    "        if params[\"amino_acids\"]:\n",
    "            all_amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "            seq = pose.sequence()        \n",
    "            # use the native ordering to generate features\n",
    "            for i in range(len(vertice_arr)):\n",
    "                i_ind = vertice_arr[i]\n",
    "                if i_ind != None:\n",
    "                    res = seq[i_ind - 1]\n",
    "                    j = all_amino_acids.find(res)\n",
    "                    self.V[i][j] = 1\n",
    "            counter_F += 20\n",
    "        \n",
    "        # Sinusoidal Positional Encoding\n",
    "        if num_dim_sine != 0:\n",
    "            if not substrate_indices.any() and not interface_indices.any():\n",
    "                n_position = N\n",
    "                position_enc = np.array([\n",
    "                    [pos / np.power(10000, 2*i/num_dim_sine) for i in range(num_dim_sine)]\n",
    "                    if pos != 0 else np.zeros(num_dim_sine) for pos in range(n_position)])\n",
    "                position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "                position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "                self.V[0:n_position,counter_F:(counter_F + num_dim_sine)] = position_enc\n",
    "            elif substrate_indices.any() and interface_indices.any():\n",
    "                # add substrates\n",
    "                n_position = len(substrate_indices)\n",
    "                position_enc = np.array([\n",
    "                    [pos / np.power(10000, 2*i/num_dim_sine) for i in range(num_dim_sine)]\n",
    "                    if pos != 0 else np.zeros(num_dim_sine) for pos in range(n_position)])\n",
    "                position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "                position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "                \n",
    "                for i in range(len(substrate_indices)):\n",
    "                    if substrate_indices[i] != None:\n",
    "                        self.V[i, counter_F:(counter_F + num_dim_sine)] = position_enc[i, :]\n",
    "                # add interface\n",
    "                n_position = len(pose.sequence()) - len(substrate_indices)\n",
    "                position_enc = np.array([\n",
    "                    [pos / np.power(10000, 2*i/num_dim_sine) for i in range(num_dim_sine)]\n",
    "                    if pos != 0 else np.zeros(num_dim_sine) for pos in range(n_position)])\n",
    "                position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "                position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "                for i in range(N - len(substrate_indices)):\n",
    "                    if interface_indices[i] != None:\n",
    "                        self.V[(len(substrate_indices) + i), counter_F:(counter_F + num_dim_sine)] = position_enc[i, :]\n",
    "            else:\n",
    "                # add substrates\n",
    "                n_position = len(substrate_indices)\n",
    "                position_enc = np.array([\n",
    "                    [pos / np.power(10000, 2*i/num_dim_sine) for i in range(num_dim_sine)]\n",
    "                    if pos != 0 else np.zeros(num_dim_sine) for pos in (substrate_indices - substrate_indices[0])])\n",
    "                position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
    "                position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
    "                self.V[0:n_position,counter_F:(counter_F + num_dim_sine)] = position_enc\n",
    "            counter_F += num_dim_sine\n",
    "\n",
    "        # Single Body Energy Terms\n",
    "        for counter, term in enumerate(params[\"energy_terms\"], counter_F):\n",
    "            for i in range(N):\n",
    "                if vertice_arr[i] != None:\n",
    "                    self.V[i, counter] = energies.residue_total_energies(vertice_arr[i])[term]\n",
    "        counter_F += energy_terms\n",
    "\n",
    "        if params[\"coordinates\"]:\n",
    "            for i in range(len(vertice_arr)):\n",
    "                if vertice_arr[i] != None:\n",
    "                    C_alpha_coord = to_numpy(pose.residue(vertice_arr[i]).xyz(\"CA\"))\n",
    "                    self.V[i, counter_F : (counter_F + 3)] = C_alpha_coord\n",
    "            counter_F += 3\n",
    "            print(self.V[i, counter_F : (counter_F + 3)])\n",
    "        # New node feature\n",
    "        \"\"\"\n",
    "        if params[\"new feature\"]:\n",
    "            self.V[:, counter_F] = whatever\n",
    "            counter_F += 1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Substrate boolean\n",
    "        if params[\"substrate_boolean\"]:\n",
    "            self.V[0:len(substrate_indices),counter_F] = np.array([1 for x in range(len(substrate_indices))])\n",
    "\n",
    "        # Total Two Body Energy and Energy Terms\n",
    "        if len(params[\"energy_edge_terms\"]) != 0:\n",
    "            for i in range(len(vertice_arr)):\n",
    "                for j in range(i, len(vertice_arr)):\n",
    "                    if vertice_arr[i] != None and vertice_arr[j] != None:\n",
    "                        if i != j:\n",
    "                            rsd1 = pose.residue(vertice_arr[i])\n",
    "                            rsd2 = pose.residue(vertice_arr[j])\n",
    "                            emap = EMapVector()\n",
    "                            sfxn.eval_ci_2b(rsd1, rsd2, pose, emap)\n",
    "                            for counter, term in enumerate(params[\"energy_edge_terms\"]):\n",
    "                                self.A[i, j, counter_M + counter] = emap[term]\n",
    "                                self.A[j, i, counter_M + counter] = emap[term]\n",
    "            counter_M += len(params[\"energy_edge_terms\"])\n",
    "\n",
    "        # Hydrogen Bonding Energies\n",
    "        if params[\"hbond\"]:\n",
    "            hbs=pose.get_hbonds()\n",
    "            res_dict = dict()\n",
    "            for res in vertice_arr:\n",
    "                hbl = hbs.residue_hbonds(res)\n",
    "                for hb in hbl:\n",
    "                    residues = (hb.don_res(), hb.acc_res())\n",
    "                    if residues[0] > residues[1]: residues = (hb.acc_res(), hb.don_res())\n",
    "                    if residues[0] in vertice_arr and residues[1] in vertice_arr: res_dict[residues] = hb.energy()\n",
    "            for residues in res_dict:\n",
    "                for i in np.where(vertice_arr==residues[0])[0]:\n",
    "                    for j in np.where(vertice_arr==residues[1])[0]:\n",
    "                        self.A[i,j,counter_M] += self.A[i,j,counter_M] + res_dict[residues]\n",
    "                        self.A[j,i,counter_M] += self.A[j,i,counter_M] + res_dict[residues]\n",
    "            counter_M += 1\n",
    "\n",
    "        # Protease - Substrate Interactions Boolean\n",
    "        if params[\"interface_edge\"]:\n",
    "            self.A[0:len(substrate_indices), len(substrate_indices):len(vertice_arr), counter_M] = 1\n",
    "            self.A[len(substrate_indices):len(vertice_arr), 0:len(substrate_indices), counter_M] = 1\n",
    "            counter_M += 1\n",
    "\n",
    "        # Covalent Bond Connection Boolean\n",
    "        if params[\"covalent_edge\"]:\n",
    "            for i in range(len(vertice_arr) - 1):\n",
    "                if vertice_arr[i + 1] - vertice_arr[i] == 1:\n",
    "                    self.A[i, i + 1, counter_M] = 1\n",
    "                    self.A[i + 1, i, counter_M] = 1\n",
    "            counter_M += 1\n",
    "        print(vertice_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goes from a sequence to a graph representation.\n",
    "def generate_graph(seq, pr_path, substrate_ind, interface_ind, params, sfxn):\n",
    "    pose = get_pose(seq, pr_path)\n",
    "    if type(pose) == type(\"string\"):\n",
    "        return pose\n",
    "    g = protein_graph(pose = pose,\n",
    "                       substrate_indices = cutsite_ind,\n",
    "                       interface_indices = interface_ind,\n",
    "                       sfxn = sfxn,\n",
    "                       params = params)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mcore.io.silent.SilentFileData: \u001b[0mReading all structures from /Users/cplu/Downloads/Documents/RESEARCH/GCNN/protease-gcnn-pytorch/graph/bin/AYYYEPC.ASHL54063\n",
      "\u001b[0mcore.io.silent.SilentFileData: \u001b[0mFinished reading 1 structures from /Users/cplu/Downloads/Documents/RESEARCH/GCNN/protease-gcnn-pytorch/graph/bin/AYYYEPC.ASHL54063\n",
      "[198 199 200 201 202  51  52  53  55  56  57  58  59  69  70  71  72  73\n",
      "  74  75  96 123 124 138 147 148 149 150 151 152 153 154 155 156 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183]\n"
     ]
    }
   ],
   "source": [
    "gg =generate_graph(\"AYYYEPC.ASHL\",\"silent\",substrate_ind,interface_ind,params,sfxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"amino_acids\":True,\n",
    "                \"sinusoidal_encoding\":2,\n",
    "#                 \"cosine_similarity\":False,\n",
    "                \"coordinates\": False,\n",
    "                \"substrate_boolean\":True,\n",
    "                \"energy_terms\":[fa_intra_sol_xover4, fa_intra_rep, rama_prepro, omega, p_aa_pp, fa_dun, ref],\n",
    "                \"energy_edge_terms\":[fa_atr, fa_rep, fa_sol, fa_elec, lk_ball_wtd],\n",
    "                \"hbond\": True,\n",
    "                \"interface_edge\": True,\n",
    "                \"covalent_edge\": True,\n",
    "#                 \"distance\":True,\n",
    "#                 \"energy\":True\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198 199 200 201 202  51  52  53  55  56  57  58  59  69  70  71  72  73\n",
      "  74  75  96 123 124 138 147 148 149 150 151 152 153 154 155 156 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183]\n"
     ]
    }
   ],
   "source": [
    "g = protein_graph(pose = pose,\n",
    "                       substrate_indices = cutsite_ind,\n",
    "                       interface_indices = interface_ind,\n",
    "                       sfxn = sfxn,\n",
    "                       params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.24161177,  4.16952966, -0.49597924,\n",
       "        0.02561926,  0.09068901,  3.8212185 ,  0.58223   ,  1.        ])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg.V[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 30), (49, 49, 10))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.V.shape, g.A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"aa1\",\"aa2\",\"aa3\",\"aa4\",\"aa5\",\"aa6\",\"aa7\",\"aa8\",\"aa9\",\"aa10\",\n",
    "          \"aa11\",\"aa12\",\"aa13\",\"aa14\",\"aa15\",\"aa16\",\"aa17\",\"aa18\",\"aa19\",\"aa20\",\n",
    "          \"sin1\",\"sin2\",\"fa_intra_sol_xover4\", \"fa_intra_rep\", \"rama_prepro\", \n",
    "           \"omega\", \"p_aa_pp\", \"fa_dun\", \"ref\",\"is_substrate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(g.V, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa1</th>\n",
       "      <th>aa2</th>\n",
       "      <th>aa3</th>\n",
       "      <th>aa4</th>\n",
       "      <th>aa5</th>\n",
       "      <th>aa6</th>\n",
       "      <th>aa7</th>\n",
       "      <th>aa8</th>\n",
       "      <th>aa9</th>\n",
       "      <th>aa10</th>\n",
       "      <th>...</th>\n",
       "      <th>sin1</th>\n",
       "      <th>sin2</th>\n",
       "      <th>fa_intra_sol_xover4</th>\n",
       "      <th>fa_intra_rep</th>\n",
       "      <th>rama_prepro</th>\n",
       "      <th>omega</th>\n",
       "      <th>p_aa_pp</th>\n",
       "      <th>fa_dun</th>\n",
       "      <th>ref</th>\n",
       "      <th>is_substrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241612</td>\n",
       "      <td>4.169530</td>\n",
       "      <td>-0.495979</td>\n",
       "      <td>0.025619</td>\n",
       "      <td>0.090689</td>\n",
       "      <td>3.821219</td>\n",
       "      <td>0.58223</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.268187</td>\n",
       "      <td>4.235788</td>\n",
       "      <td>0.959456</td>\n",
       "      <td>1.152130</td>\n",
       "      <td>-0.566650</td>\n",
       "      <td>2.408025</td>\n",
       "      <td>0.58223</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.286675</td>\n",
       "      <td>4.379675</td>\n",
       "      <td>1.205627</td>\n",
       "      <td>-0.092665</td>\n",
       "      <td>0.053928</td>\n",
       "      <td>4.067401</td>\n",
       "      <td>0.58223</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297897</td>\n",
       "      <td>1.398956</td>\n",
       "      <td>1.115776</td>\n",
       "      <td>-0.055925</td>\n",
       "      <td>0.326248</td>\n",
       "      <td>4.119510</td>\n",
       "      <td>-2.72453</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116397</td>\n",
       "      <td>0.797717</td>\n",
       "      <td>0.684848</td>\n",
       "      <td>1.322425</td>\n",
       "      <td>-1.481414</td>\n",
       "      <td>0.895828</td>\n",
       "      <td>-1.64321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa1  aa2  aa3  aa4  aa5  aa6  aa7  aa8  aa9  aa10  ...      sin1  sin2  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...  0.000000   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...  0.841471   1.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...  0.909297   1.0   \n",
       "3  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   0.0  ...  0.141120   1.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ... -0.756802   1.0   \n",
       "\n",
       "   fa_intra_sol_xover4  fa_intra_rep  rama_prepro     omega   p_aa_pp  \\\n",
       "0             0.241612      4.169530    -0.495979  0.025619  0.090689   \n",
       "1             0.268187      4.235788     0.959456  1.152130 -0.566650   \n",
       "2             0.286675      4.379675     1.205627 -0.092665  0.053928   \n",
       "3             0.297897      1.398956     1.115776 -0.055925  0.326248   \n",
       "4             0.116397      0.797717     0.684848  1.322425 -1.481414   \n",
       "\n",
       "     fa_dun      ref  is_substrate  \n",
       "0  3.821219  0.58223           1.0  \n",
       "1  2.408025  0.58223           1.0  \n",
       "2  4.067401  0.58223           1.0  \n",
       "3  4.119510 -2.72453           1.0  \n",
       "4  0.895828 -1.64321           1.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"fa_atr\", \"fa_rep\", \"fa_sol\", \"fa_elec\", \"lk_ball_wtd\", \"hbond\",\n",
    "        \"link_interface_substrate\",\"is_covalent\"]\n",
    "df_edge = pd.DataFrame(g.A[1], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0., 2401.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.]),\n",
       " array([-0.5  , -0.475, -0.45 , -0.425, -0.4  , -0.375, -0.35 , -0.325,\n",
       "        -0.3  , -0.275, -0.25 , -0.225, -0.2  , -0.175, -0.15 , -0.125,\n",
       "        -0.1  , -0.075, -0.05 , -0.025,  0.   ,  0.025,  0.05 ,  0.075,\n",
       "         0.1  ,  0.125,  0.15 ,  0.175,  0.2  ,  0.225,  0.25 ,  0.275,\n",
       "         0.3  ,  0.325,  0.35 ,  0.375,  0.4  ,  0.425,  0.45 ,  0.475,\n",
       "         0.5  ]),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(g.A[:,:,5].flatten(),bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pro_close, hbond_sc = 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(g.A[:,:,7].flatten()!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  3,  3,  5,  6,  7,  7,  7,  8,  9,  9,  9, 10, 11, 12, 12, 13,\n",
       "        13, 14, 14, 14, 15, 15, 16, 16, 17, 17, 18, 19, 20, 20, 20, 22, 22,\n",
       "        22, 23, 24, 24, 27, 28, 28, 29, 30, 30, 30, 31, 32, 33, 33, 34, 34,\n",
       "        35, 35, 36, 37, 38, 38, 39, 40, 42, 43, 45, 46, 48, 48, 48]),\n",
       " array([39, 28, 37, 11,  7,  6,  8,  9,  7,  7, 16, 17, 22,  5, 13, 31, 12,\n",
       "        14, 13, 17, 18, 19, 20,  9, 20,  9, 14, 14, 15, 15, 16, 35, 10, 29,\n",
       "        30, 48, 28, 42, 30,  3, 24, 22, 22, 27, 33, 12, 34, 30, 34, 32, 33,\n",
       "        20, 48, 48,  3, 45, 46,  1, 43, 24, 40, 38, 38, 23, 35, 36]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(g.A[:,:,7]!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbs=pose.get_hbonds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertice_arr = \"198 199 200 201 202  51  52  53  55  56  57  58  59  69  70  71  72  73  74  75  96 123 124 138 147 148 149 150 151 152 153 154 155 156 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\".split(\" \")\n",
    "while '' in vertice_arr:\n",
    "    vertice_arr.pop(vertice_arr.index(''))\n",
    "vertice_arr = [int(x) for x in vertice_arr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 don: protein backbone 174 7 acc: protein backbone 199 4 -1.38681 1\n",
      "\n",
      "174 199\n"
     ]
    }
   ],
   "source": [
    "for hb in hbs.residue_hbonds(199):\n",
    "    print(hb)\n",
    "    print(hb.don_res(),hb.acc_res())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    #preset\n",
    "    pr.init()\n",
    "    sfxn = get_fa_scorefxn()\n",
    "    classifier_path = \"classifications/\"\n",
    "    data_path = \"../data\" \n",
    "    pdb_path = \"crystal_structures\"\n",
    "    \n",
    "    class_file = args.class #list of samples\n",
    "    output = args.output \n",
    "    pr_path = args.protease_path\n",
    "    index_p1 = args.index_p1\n",
    "    protease = args.protease\n",
    "    dis = args.select_sequence\n",
    "    \n",
    "    logger = get_logger(logpath=os.path.join(data_path, 'logs'), filepath=os.path.abspath(__file__))\n",
    "    \n",
    "    params = {\"amino_acids\":True,\n",
    "                \"sinusoidal_encoding\":2,\n",
    "                \"coordinates\": False,\n",
    "                \"substrate_boolean\":True,\n",
    "                \"energy_terms\":[fa_intra_sol_xover4, fa_intra_rep, rama_prepro, omega, p_aa_pp, fa_dun, ref],\n",
    "                \"energy_edge_terms\":[fa_atr, fa_rep, fa_sol, fa_elec, lk_ball_wtd],\n",
    "                \"hbond\": True,\n",
    "                \"interface_edge\": True,\n",
    "                \"covalent_edge\": True,}\n",
    "    logger.info(\"Features Info: {}\".format(params))\n",
    "    \n",
    "    cutsite_ind, interface_ind = get_ind_from_protease(args.protease, pdb_path, index_p1, d, sfxn)\n",
    "    logger.info(\"Focus substrate indices are {}\".format(','.join(cutsite_ind)))\n",
    "    logger.info(\"Neighbor residues indices are {}\".format(','.join(interface_ind)))\n",
    "    \n",
    "    # Read in labels and sequences\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(classifier_path, class_file), sep = \"\\t\")\n",
    "        labels = list(df[\"Result\"])\n",
    "        sequences = list(df[\"Sequence\"])\n",
    "    except:\n",
    "        raise ValueError(\"Path either invalid to classsifications or not properly formatted. \\\n",
    "    Please check template sample.txt\")\n",
    "    \n",
    "    # get all graphs into a list\n",
    "    missed_sequences = []\n",
    "    error_sequences = []\n",
    "    seq_final = []\n",
    "    label_final = []\n",
    "    graphs = []\n",
    "    for i in range(len(sequences)):\n",
    "        seq = sequences[i]\n",
    "        graph = generate_graph(seq, pr_path, cutsite_ind, interface_ind)\n",
    "        logger.info(\"Graph for {} has been generated successfully.\".format(seq))\n",
    "        if graph == \"Error: No Silent\":\n",
    "            missed_sequences.append(seq)\n",
    "        elif graph == \"Error: Invalid Silent\":\n",
    "            error_sequences.append(seq)\n",
    "        else:\n",
    "            seq_final.append(seq)\n",
    "            graphs.append(graph)\n",
    "            label_final.append(labels[i])\n",
    "    \n",
    "    logger.info(\"There were {} poses which loaded\".format(len(graphs)))\n",
    "    logger.info(\"There were {} poses missing due to silent files.\".format(len(missed_sequences)))\n",
    "    logger.info(\"There were {} poses which failed to be loaded.\".format(len(error_sequences)))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    main(args)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pkl.load(open(os.path.join(data_path, \"ind.sample.x\"),\"rb\"))\n",
    "y = pkl.load(open(os.path.join(data_path, \"ind.sample.y\"),\"rb\"))\n",
    "graph = pkl.load(open(os.path.join(data_path,\"ind.sample.graph\"),\"rb\"))\n",
    "labelorder = pkl.load(open(os.path.join(data_path,\"ind.sample.labelorder\"),\"rb\"))\n",
    "sequences = pkl.load(open(os.path.join(data_path,\"ind.sample.sequences\"),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
